{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb8d69c-3c15-4cd8-9280-143a6187b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  projectCode.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a29947-3c42-441b-9335-d305bb567c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "ann_file = \"./annotations/annotations/captions_val2017.json\"\n",
    "num_examples = 512\n",
    "batch_size = 1\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8324fa15-a2bd-4135-9b73-87eb8a322e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Selected 512 images.\n",
      "Downloading images\n"
     ]
    }
   ],
   "source": [
    "ds = CocoDataset(ann_file, num_examples, img_dir = \"imgs\",seed = seed)\n",
    "dl = DataLoader(ds, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee21067-8b6f-440e-880b-fa6fe421f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/captioning/miniconda3/envs/captioning/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538459595/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/captioning/236874/projectCode/ModelLoader.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model_params={\"device\":device,\"tokens_path\":'./models/ExpansionNet_v2/demo_material/demo_coco_tokens.pickle',\"blur_kernel_size\":5,\"blured\":True}\n",
    "model = loadModel(\"ExpansionNet\",model_path=\"./models/ExpansionNet_v2/rf_model.pth\",**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c18be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_attack = 25\n",
    "base = \"./adversarial_attacks\"+\"/ExpNet\"+\"/blured\"+f\"/it{iter_per_attack}_exNum{num_examples}\"\n",
    "attacks_file_name = base + \".pt\" \n",
    "captions_file = base+\".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f0a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/512 [00:22<3:09:16, 22.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m attacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dl):\n\u001b[0;32m----> 7\u001b[0m     pert \u001b[38;5;241m=\u001b[39m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturbExpNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     attacks\u001b[38;5;241m.\u001b[39mappend(pert)\n\u001b[1;32m      9\u001b[0m perts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(attacks)\n",
      "File \u001b[0;32m~/236874/projectCode/attack.py:160\u001b[0m, in \u001b[0;36mAttacker.perturbExpNet\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m lll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(l1,l2)\n\u001b[1;32m    158\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out_clear[:ll,:lll],out_pert[:ll,:lll])\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)            \n\u001b[0;32m--> 160\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    164\u001b[0m dulta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(delta)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/captioning/lib/python3.10/site-packages/torch/_tensor.py:465\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    467\u001b[0m ):\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m            used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GENERATING ADVERSARIAL EXAMPLES\n",
    "if not os.path.exists(attacks_file_name):\n",
    "    attacker = Attacker(model,torch.nn.MSELoss(),device, num_iterations=iter_per_attack)\n",
    "    attacks = []\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        pert = attacker.perturbExpNet(batch[0])\n",
    "        attacks.append(pert)\n",
    "    perts = torch.cat(attacks)\n",
    "    torch.save(perts,attacks_file_name)\n",
    "else:\n",
    "    perts = torch.load(attacks_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a279d9-b631-4d34-860e-59afa48ff848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304160/1313045100.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  perts = torch.load(f\"ExpNet_{num_examples}_pert_v2.pt\")\n"
     ]
    }
   ],
   "source": [
    "captions = None\n",
    "caps = None\n",
    "\n",
    "#use if exists already\n",
    "if  os.path.exists(captions_file):\n",
    "    with open(captions_file, 'r') as openfile:\n",
    "        captions = json.load(openfile)\n",
    "        if \"captions\" in captions.keys():\n",
    "            caps = captions[\"captions\"]\n",
    "    \n",
    "if caps is None:\n",
    "    cas = []\n",
    "    for i in range(num_examples):\n",
    "        x = ds[i]\n",
    "        pert = perts[i]\n",
    "        \n",
    "        out, _, _, _ = model(x[0].to(device)) # prediction, pred_probs, logits, cross_enc_output\n",
    "        print(out)\n",
    "        p_out, _, _, _ = model(torch.clamp(x[0].to(device)+pert.to(device),0,1))\n",
    "        caps.append((out,p_out))\n",
    "\n",
    "    if captions is None:\n",
    "        captions =  {\n",
    "        \"seed\": seed,\n",
    "        \"num_examples\": num_examples,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"captions\": caps\n",
    "        }\n",
    "    else:\n",
    "        captions[\"captions\"] = caps\n",
    "\n",
    "    with open(captions_file, 'w') as openfile:\n",
    "            json.dump(captions,openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536025e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ExpNet_512_1_cap_v2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m out_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ExpNet_512_1_cap_v2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m openfile:\n\u001b[1;32m      7\u001b[0m     captions \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(openfile)\n\u001b[1;32m      9\u001b[0m caps \u001b[38;5;241m=\u001b[39m captions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaptions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/captioning/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ExpNet_512_1_cap_v2.json'"
     ]
    }
   ],
   "source": [
    "#use if already exists\n",
    "if \"scores\" in captions.keys():\n",
    "    meteor_scores = captions[\"scores\"][\"meteor\"]\n",
    "\n",
    "else:\n",
    "    meteor_scores=[]\n",
    "    for caps,ex in zip(caps,ds):\n",
    "        c_clear = caps[0]\n",
    "        c_corr = caps[1]\n",
    "        img = ex[0]\n",
    "\n",
    "        anot = [an[0] for an in ex[1]]\n",
    "        \n",
    "        score =  meteor_eval_single(anot,c_clear[0])\n",
    "        score_corr = meteor_eval_single(anot,c_corr[0])\n",
    "        \n",
    "        \n",
    "        meteor_scores.append((score,score_corr))#,out,p_out)) #img, delta, model_output, model_output_corrupted\n",
    "\n",
    "    captions[\"scores\"]={}\n",
    "    captions[\"scores\"][\"meteor\"] = meteor_scores\n",
    "\n",
    "    with open(captions_file, 'w') as openfile:\n",
    "        json.dump(captions,openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68293549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attack statistics\")\n",
    "t = torch.tensor([list(p) for p in meteor_scores])\n",
    "diff = t[:,0]-t[:,1]\n",
    "avg = diff.mean()\n",
    "print(\"Average reduction in meteor score:\",avg)\n",
    "improve = (diff<0)\n",
    "print(\"Number of samples that improved score:\",improve.sum(), \"out of 512\")\n",
    "print(\"The average improvement rate:\",-diff[improve].mean())\n",
    "filter = t[:,0]>0.45\n",
    "tf = t[filter]\n",
    "diff = tf[:,0]-tf[:,1]\n",
    "avg = diff.mean()\n",
    "print(\"Average reduction in meteor score for images with high initial score:\",avg)\n",
    "improve = (diff<0)\n",
    "print(\"Number of samples that improved high initial score:\",improve.sum(), \"out of 512\")\n",
    "print(\"The average improvement rate:\",-diff[improve].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
