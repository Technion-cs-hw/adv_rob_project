{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8d69c-3c15-4cd8-9280-143a6187b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import sys \n",
    "import json\n",
    "from argparse import Namespace\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "sys.path.append(\"./models/ExpansionNet_v2\")\n",
    "from projectCode.ModelLoader import loadModel\n",
    "from projectCode.CocoDataset import CocoDataset\n",
    "from projectCode.Perturbator import *\n",
    "from projectCode.Evaluator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c349f1d-5170-47d1-8df3-44d482afab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a29947-3c42-441b-9335-d305bb567c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = \"./annotations/annotations/captions_val2017.json\"\n",
    "num_examples = 256\n",
    "seed = 42\n",
    "\n",
    "ds = CocoDataset(ann_file, num_examples, img_dir = \"imgs\",seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c8b48-978d-4e69-9178-a6497df0efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\"device\":device,\"tokens_path\":'./models/ExpansionNet_v2/demo_material/demo_coco_tokens.pickle'}\n",
    "model = loadModel(\"ExpansionNet\",model_path=\"./models/ExpansionNet_v2/rf_model.pth\",**model_params)\n",
    "#model = loadModel(\"BLIP\",model_path = None, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa3c32-3f89-413b-b355-7edd0f735e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "corruption_types = [Perturbation(), \n",
    "                    Blur(), \n",
    "                    Noise(noise_level = 0.12),\n",
    "                    Noise(noise_type = \"Uniform\",noise_level = 0.33),\n",
    "                    Noise(noise_type =\"Laplace\",noise_level = 0.1), \n",
    "                    Patch(patch_size = (50,50))]\n",
    "\"\"\"\n",
    "corruption_types = [Mirror(axis=[-2,-1]),\n",
    "                    Mirror(axis=[-1]),\n",
    "                    Perspective(),\n",
    "                    RandomRotation(),\n",
    "                    #Grayscale(),\n",
    "                    ColorJitter()]\n",
    "evaluator = Evaluator(model,ds,corruption_types,\"METEOR\",batch_size=4, seed=seed, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32781c2-cb03-4a44-8c71-688c858e537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "imgs = [ds[i][0] for i in range(3)]\n",
    "b = torch.stack(imgs)\n",
    "print(b.shape)\n",
    "\n",
    "transform = T.ToPILImage()\n",
    "for c in corruption_types:\n",
    "    img_c = c.apply(b[0])\n",
    "    img_pil = transform(img_c)\n",
    "    plt.imshow(img_pil)  # Use cmap=\"gray\" for grayscale images\n",
    "    plt.axis(\"off\")  # Hide axis\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04c94f-589d-44fa-a03a-45e3a11fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluator.evaluate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4b2fc-f974-450b-a615-f11b5b10f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tensor = torch.tensor(scores)\n",
    "\n",
    "\"\"\"\n",
    "result = {\n",
    "    \"seed\": seed,\n",
    "    \"corruption_types\":['id','blur','normal noise','uniform noise','laplace noise','patch'],\n",
    "    \"scores\": {\n",
    "        \"id\": scores_tensor[0].mean().item(),\n",
    "        \"blur\": scores_tensor[1].mean().item(),\n",
    "        \"normal noise\": scores_tensor[2].mean().item(),\n",
    "        \"uniform noise\": scores_tensor[3].mean().item(),\n",
    "        \"laplace noise\": scores_tensor[4].mean().item(),\n",
    "        \"patch\": scores_tensor[5].mean().item(),\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = {\n",
    "    \"seed\": seed,\n",
    "    \"corruption_types\":['mirror_lr','mirror_ud','random_perspective','random_rotation','random_color'],\n",
    "    \"scores\": {\n",
    "        \"mirror_lr\": scores_tensor[0].mean().item(),\n",
    "        \"mirror_ud\": scores_tensor[1].mean().item(),\n",
    "        \"random_perspective\": scores_tensor[2].mean().item(),\n",
    "        \"random_rotation\": scores_tensor[3].mean().item(),\n",
    "        \"random_color\": scores_tensor[4].mean().item(),\n",
    "    }\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcdd80-9ca5-41fe-bf4e-7ce35e245da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ExpansionNet_256_BLEU_Mirror_Perspective_Rotation_Color.json\"\n",
    "\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(result, json_file)\n",
    "\n",
    "print(f\"Results have been saved to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
