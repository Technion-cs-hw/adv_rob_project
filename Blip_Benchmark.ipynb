{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb8d69c-3c15-4cd8-9280-143a6187b459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/captioning/miniconda3/envs/captioning/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/captioning/miniconda3/envs/captioning/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/captioning/miniconda3/envs/captioning/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/captioning/miniconda3/envs/captioning/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import sys \n",
    "import json\n",
    "from argparse import Namespace\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"./models/ExpansionNet_v2\")\n",
    "from projectCode.ModelLoader import loadModel\n",
    "from projectCode.CocoDataset import CocoDataset\n",
    "from projectCode.Perturbator import *\n",
    "from projectCode.Evaluator import *\n",
    "\n",
    "from projectCode.attack import Attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdcd961-dd61-47c7-a8a2-8d673af9076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a29947-3c42-441b-9335-d305bb567c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Selected 256 images.\n",
      "Downloading images\n"
     ]
    }
   ],
   "source": [
    "ann_file = \"./annotations/annotations/captions_val2017.json\"\n",
    "num_examples = 256\n",
    "\n",
    "seed = 42\n",
    "\n",
    "ds = CocoDataset(ann_file, num_examples, img_dir = \"imgs\",seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017c8b48-978d-4e69-9178-a6497df0efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"BLIP\",model_path = None, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa3c32-3f89-413b-b355-7edd0f735e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_types = [Perturbation(), \n",
    "                    Blur(), \n",
    "                    Noise(noise_level = 0.12),\n",
    "                    Noise(noise_type = \"Uniform\",noise_level = 0.33),\n",
    "                    Noise(noise_type =\"Laplace\",noise_level = 0.1), \n",
    "                    Patch(patch_size = (50,50))]\n",
    "evaluator = Evaluator(model,ds,corruption_types,\"BLEU\",batch_size=64, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66f0bf-1d33-40d4-8f91-c474d2f1d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = []\n",
    "filtered_cap = []\n",
    "for img, cap in ds:\n",
    "    p = model(img.unsqueeze(0))\n",
    "    score = METEOR_eval([cap], p)\n",
    "    if score[0] >= 0.45:\n",
    "        filtered_img.append(img)\n",
    "        filtered_cap.append(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacd4ac-5c6b-4aae-9cad-17a03a1a5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_tensor = torch.stack(filtered_img)\n",
    "\n",
    "captions = {\n",
    "    \"captions\": filtered_cap\n",
    "}\n",
    "\n",
    "file_name = \"captions_filtered.json\"\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(captions, json_file)\n",
    "\n",
    "file_name = \"img_filtered\"\n",
    "torch.save(filtered_img_tensor, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04c94f-589d-44fa-a03a-45e3a11fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluator.evaluate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4b2fc-f974-450b-a615-f11b5b10f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tensor = torch.tensor(scores)\n",
    "\n",
    "result = {\n",
    "    \"seed\": seed,\n",
    "    \"corruption_types\": ['id','blur','normal noise','uniform noise','laplace noise','patch'],\n",
    "    \"scores\": {\n",
    "        \"id\": scores_tensor[0].mean().item(),\n",
    "        \"blur\": scores_tensor[1].mean().item(),\n",
    "        \"normal noise\": scores_tensor[2].mean().item(),\n",
    "        \"uniform noise\": scores_tensor[3].mean().item(),\n",
    "        \"laplace noise\": scores_tensor[4].mean().item(),\n",
    "        \"patch\": scores_tensor[5].mean().item(),\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcdd80-9ca5-41fe-bf4e-7ce35e245da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"BLIP_BLUP_256_BLEU_Blur_Noise_Patch.json\"\n",
    "\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(result, json_file)\n",
    "\n",
    "print(f\"Results have been saved to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
